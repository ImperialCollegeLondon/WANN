{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score,mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from adapt.feature_based import DANN\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=0.01)\n",
    "def get_MLP():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(64,input_dim=6,activation=\"relu\"))\n",
    "    model.add(Dense(256,activation=\"relu\",))\n",
    "    model.add(Dense(256,activation=\"relu\",))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\",optimizer=adam)\n",
    "    return model\n",
    "def get_DANN(Xs,ys,Xt_train):    \n",
    "    model = DANN(task=get_MLP(),lambda_=0.1, Xt=Xt_train, metrics=[\"acc\"])\n",
    "    model.fit(Xs, ys, epochs=100, verbose=0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input data\n",
    "path_drill_logging = r'drilling.xlsx'\n",
    "path_bit = r'BitRecord.xlsx'\n",
    "data = pd.read_csv(path_drill_logging)\n",
    "bit = pd.read_excel(path_bit)\n",
    "#data preprocessing\n",
    "scaler = StandardScaler()\n",
    "columns_to_standardize = []\n",
    "scaler.fit(data[columns_to_standardize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP model\n",
    "#bitsize can be '26\"','16\"','12-1/4\"','8-1/2\"','6\"'\n",
    "size = '26\"'\n",
    "same_size_bit = bit[bit['Bit']== size]\n",
    "#select a bit to predict\n",
    "well = 1\n",
    "topdepth = 3000\n",
    "botdepth = 3546\n",
    "footages = 546\n",
    "#get the nowear data of the bit\n",
    "nowear_data = data[(data['Well']==well)&(data['Depth']>topdepth)&(data['Depth']<=topdepth+30)].loc[:,:]\n",
    "wear_data = data[(data['Well']==well)&(data['Depth']>topdepth+30)&(data['Depth']<=botdepth)].loc[:,:]\n",
    "#get the left same size data of the bit\n",
    "#same_size_bit number\n",
    "bit_num = len(same_size_bit)\n",
    "allnowear_data = []\n",
    "for i in range(bit_num):\n",
    "    well = same_size_bit.iloc[i,1]\n",
    "    topdepth = same_size_bit.iloc[i,2]\n",
    "    botdepth = same_size_bit.iloc[i,3]\n",
    "    footages = same_size_bit.iloc[i,4]\n",
    "    allnowear_data.append(data[(data['Well']==well)&(data['Depth']>topdepth)&(data['Depth']<=topdepth+30)].loc[:,:])\n",
    "allnowear_data = pd.concat(allnowear_data)\n",
    "leftnowear_data = allnowear_data.drop(nowear_data.index)\n",
    "print('nowear_data number:',len(nowear_data))\n",
    "print('leftnowear_data number:',len(leftnowear_data))\n",
    "#Set the nowear bit data as 7; 3 Divide the training set and test set\n",
    "features = ['Depth','WOB','RPM','TORQUE','FLWpmps','Density','DT','GR']\n",
    "xt = nowear_data.loc[:,features].values\n",
    "xt = scaler.transform(xt)\n",
    "yt = nowear_data.loc[:,['ROP m/hr']].values\n",
    "Xt_train, Xt_test, yt_train, yt_test = train_test_split(xt, yt, test_size=0.3, random_state=0)\n",
    "#将left_bit_data和Xt_train合并\n",
    "Xs = leftnowear_data.loc[:,features].values\n",
    "Xs = scaler.transform(Xs)\n",
    "ys = leftnowear_data.loc[:,['ROP m/hr']].values\n",
    "# Xs = np.concatenate((Xs,Xt_train),axis=0)\n",
    "# ys = np.concatenate((ys,yt_train),axis=0)\n",
    "#train model\n",
    "model = get_MLP()\n",
    "model.fit(Xs,ys,epochs=100)\n",
    "#model=get_WANN(Xs,ys,Xt_train,yt_train)\n",
    "yt_pred=model.predict(Xt_test)\n",
    "#evaluation\n",
    "MLP_r2 = r2_score(yt_test,yt_pred)\n",
    "MLP_mape =mean_absolute_percentage_error(yt_test,yt_pred)\n",
    "print('R2:',MLP_r2)\n",
    "print('MAPE:',MLP_mape)\n",
    "#predict wear data to get the wf\n",
    "wear_x = wear_data.loc[:,features].values\n",
    "wear_y = wear_data.loc[:,['ROP m/hr']].values\n",
    "wear_x = scaler.transform(wear_x)\n",
    "pred_y = model.predict(wear_x)\n",
    "wear_data['ROP0'] = pred_y\n",
    "wear_data['wf']=wear_data['ROP m/hr']/wear_data['ROP0']\n",
    "#save the data\n",
    "wear_data.to_csv('Pre_MLP.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DANN model\n",
    "#bitsize can be '26\"','16\"','12-1/4\"','8-1/2\"','6\"'\n",
    "size = '26\"'\n",
    "same_size_bit = bit[bit['Bit']== size]\n",
    "#select a bit to predict\n",
    "well = 1\n",
    "topdepth = 3000\n",
    "botdepth = 3546\n",
    "footages = 546\n",
    "#get the nowear data of the bit\n",
    "nowear_data = data[(data['Well']==well)&(data['Depth']>topdepth)&(data['Depth']<=topdepth+30)].loc[:,:]\n",
    "wear_data = data[(data['Well']==well)&(data['Depth']>topdepth+30)&(data['Depth']<=botdepth)].loc[:,:]\n",
    "#get the left same size data of the bit\n",
    "#same_size_bit number\n",
    "bit_num = len(same_size_bit)\n",
    "allnowear_data = []\n",
    "for i in range(bit_num):\n",
    "    well = same_size_bit.iloc[i,1]\n",
    "    topdepth = same_size_bit.iloc[i,2]\n",
    "    botdepth = same_size_bit.iloc[i,3]\n",
    "    footages = same_size_bit.iloc[i,4]\n",
    "    allnowear_data.append(data[(data['Well']==well)&(data['Depth']>topdepth)&(data['Depth']<=topdepth+30)].loc[:,:])\n",
    "allnowear_data = pd.concat(allnowear_data)\n",
    "leftnowear_data = allnowear_data.drop(nowear_data.index)\n",
    "print('nowear_data number:',len(nowear_data))\n",
    "print('leftnowear_data number:',len(leftnowear_data))\n",
    "#Set the nowear bit data as 7; 3 Divide the training set and test set\n",
    "features = ['Depth','WOB','RPM','TORQUE','FLWpmps','Density','DT','GR']\n",
    "xt = nowear_data.loc[:,features].values\n",
    "xt = scaler.transform(xt)\n",
    "yt = nowear_data.loc[:,['ROP m/hr']].values\n",
    "Xt_train, Xt_test, yt_train, yt_test = train_test_split(xt, yt, test_size=0.3, random_state=0)\n",
    "#将left_bit_data和Xt_train合并\n",
    "Xs = leftnowear_data.loc[:,features].values\n",
    "Xs = scaler.transform(Xs)\n",
    "ys = leftnowear_data.loc[:,['ROP m/hr']].values\n",
    "Xs = np.concatenate((Xs,Xt_train),axis=0)\n",
    "ys = np.concatenate((ys,yt_train),axis=0)\n",
    "#train model\n",
    "model = get_DANN(Xs,ys,Xt_train)\n",
    "model.fit(Xs,ys,epochs=100)\n",
    "yt_pred=model.predict(Xt_test)\n",
    "#evaluation\n",
    "MLP_r2 = r2_score(yt_test,yt_pred)\n",
    "MLP_mape =mean_absolute_percentage_error(yt_test,yt_pred)\n",
    "print('R2:',MLP_r2)\n",
    "print('MAPE:',MLP_mape)\n",
    "#predict wear data to get the wf\n",
    "wear_x = wear_data.loc[:,features].values\n",
    "wear_y = wear_data.loc[:,['ROP m/hr']].values\n",
    "wear_x = scaler.transform(wear_x)\n",
    "pred_y = model.predict(wear_x)\n",
    "wear_data['ROP0'] = pred_y\n",
    "wear_data['wf']=wear_data['ROP m/hr']/wear_data['ROP0']\n",
    "#save the data\n",
    "wear_data.to_csv('Pre_DANN.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
